{"cells":[{"cell_type":"code","execution_count":61,"metadata":{"execution":{"iopub.execute_input":"2024-09-19T10:47:45.173555Z","iopub.status.busy":"2024-09-19T10:47:45.172656Z","iopub.status.idle":"2024-09-19T10:47:45.581004Z","shell.execute_reply":"2024-09-19T10:47:45.580032Z","shell.execute_reply.started":"2024-09-19T10:47:45.173513Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Shape of dataframe after dropping 30,000 rows: (28150, 11)\n","Cleaned dataset saved successfully.\n"]}],"source":["#Teamno1 \n","#Madhavan M\n","#Sriram V\n","#siddarth\n","#auston\n","\n","\n","\n","#Data preprocessing is done as the ratio of no:yes is 5:1 and saved as cleaned dataset\n","\n","import pandas as pd\n","\n","# Load the dataset from CSV\n","df = pd.read_csv('/kaggle/input/datathon/DATATHON_EVENT_DATASET.csv')\n","\n","# Drop the first 30,000 rows from the dataframe as it contains no\n","df_dropped = df.iloc[30000:].reset_index(drop=True)\n","\n","# Display the shape of the updated dataframe\n","print(\"Shape of dataframe after dropping 30,000 rows:\", df_dropped.shape)\n","\n","# Save the cleaned dataframe to a new CSV file\n","df_dropped.to_csv('cleaned_dataset.csv', index=False)\n","\n","print(\"Cleaned dataset saved successfully.\")\n"]},{"cell_type":"code","execution_count":62,"metadata":{"execution":{"iopub.execute_input":"2024-09-19T10:47:45.583711Z","iopub.status.busy":"2024-09-19T10:47:45.583015Z","iopub.status.idle":"2024-09-19T10:47:49.476867Z","shell.execute_reply":"2024-09-19T10:47:49.475900Z","shell.execute_reply.started":"2024-09-19T10:47:45.583663Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Our model\n","Accuracy: 98.21%\n","F1-Score: 0.968967114404817\n","Confusion Matrix:\n","[[7921   79]\n"," [ 122 3138]]\n","Model saved successfully.\n"]}],"source":["# Import libraries\n","import pandas as pd\n","import joblib\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n","from sklearn.compose import ColumnTransformer\n","from sklearn.pipeline import Pipeline\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.metrics import f1_score, confusion_matrix, accuracy_score\n","from sklearn.impute import SimpleImputer\n","import numpy as np\n","\n","# Load the dataset from cleaned data CSV\n","# This dataset has already undergone initial cleaning (like dropping irrelevant rows)\n","df = pd.read_csv('/kaggle/input/cleaned-dataset/cleaned_dataset.csv')\n","\n","# ---- Data Cleaning (Handling missing values, outliers) ----\n","# Using SimpleImputer to handle missing values based on the type of data.\n","# Numerical columns are filled with the median (to avoid skewing the data with extreme values).\n","# Categorical columns are filled with the most frequent value (mode) to ensure consistency.\n","numerical_cols = df.select_dtypes(include=['float64', 'int64']).columns\n","categorical_cols = df.select_dtypes(include=['object']).columns\n","\n","# Impute missing values\n","df[numerical_cols] = SimpleImputer(strategy='median').fit_transform(df[numerical_cols])\n","df[categorical_cols] = SimpleImputer(strategy='most_frequent').fit_transform(df[categorical_cols])\n","\n","# ---- Outlier Handling (Optional but can be added here if needed) ----\n","# Outliers can be identified and removed or handled based on business rules or statistical methods such as IQR or Z-score.\n","\n","# ---- Label Conversion ----\n","# Convert 'Yes'/'No' in 'Fraud' column to 1 and 0 for binary classification.\n","df['Fraud'] = df['Fraud'].map({'Yes': 1, 'No': 0})\n","\n","# ---- Drop the 'Expected_Fraud' column ----\n","# The 'Expected_Fraud' column has no predictive value (contains only 'No') and thus is removed from the dataset.\n","df = df.drop(columns=['Expected_Fraud'])\n","\n","# ---- Define Features (X) and Target (y) ----\n","# The target variable 'Fraud' is what we are trying to predict. It represents whether a transaction is fraudulent or not.\n","# All other columns are features (X) used as input to the model.\n","X = df.drop(columns=['Fraud'])  # Features\n","y = df['Fraud']  # Target (fraud label)\n","\n","# ---- Handling High Cardinality Columns ----\n","# 'Origin_ID' and 'Destination_ID' have many unique values (high cardinality).\n","# Label encoding is used to convert these categorical values into numeric labels while preserving their uniqueness.\n","label_encoder = LabelEncoder()\n","X['Origin_ID'] = label_encoder.fit_transform(X['Origin_ID'])\n","X['Destination_ID'] = label_encoder.fit_transform(X['Destination_ID'])\n","\n","# ---- One-Hot Encoding for Categorical Columns ----\n","# The 'Transaction_Type' column has a small number of unique values and is encoded using One-Hot Encoding.\n","# One-Hot Encoding creates binary columns for each category, making it easier for the model to understand categorical data.\n","categorical_cols = ['Transaction_Type']\n","preprocessor = ColumnTransformer(\n","    transformers=[('cat', OneHotEncoder(drop='first'), categorical_cols)],  # One-Hot Encoding\n","    remainder='passthrough'  # Leave numerical columns unchanged\n",")\n","\n","# ---- Create the Pipeline ----\n","# A pipeline is used to combine preprocessing steps and the model into a single workflow.\n","# The pipeline first applies One-Hot Encoding, then scales numerical data, and finally trains a Random Forest classifier.\n","pipeline = Pipeline(steps=[\n","    ('preprocessor', preprocessor),  # Preprocessing: One-Hot Encoding and pass-through other features\n","    ('scaler', StandardScaler()),  # Scale numerical features to have mean=0 and variance=1 for better model performance\n","    ('classifier', RandomForestClassifier(n_estimators=200, max_depth=10, random_state=42))  # Random Forest Model\n","])\n","\n","# ---- Splitting the Data ----\n","# The dataset is split into 60% training and 40% testing using stratification to maintain the balance between classes (fraud vs. non-fraud).\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=42, stratify=y)\n","\n","# ---- Train the Model ----\n","# The Random Forest Classifier is trained on the training set. It is an ensemble model that reduces overfitting and increases accuracy.\n","pipeline.fit(X_train, y_train)\n","\n","# ---- Predictions and Evaluation ----\n","# The trained model is used to make predictions on the test set.\n","y_pred = pipeline.predict(X_test)\n","\n","# ---- Model Performance Evaluation ----\n","# F1 Score, Confusion Matrix, and Accuracy are used to evaluate the model.\n","# F1 Score is the harmonic mean of precision and recall, suitable for imbalanced datasets like fraud detection.\n","# The confusion matrix shows true/false positives and negatives, giving insight into the types of errors.\n","f1 = f1_score(y_test, y_pred)\n","cm = confusion_matrix(y_test, y_pred)\n","accuracy = accuracy_score(y_test, y_pred)\n","\n","# Print the evaluation metrics\n","print(\"Our model\")\n","print(f'Accuracy: {accuracy * 100:.2f}%')  # High accuracy indicates the model is making correct predictions most of the time.\n","print(f'F1-Score: {f1}')  # F1 score ensures a balance between false positives and false negatives.\n","print('Confusion Matrix:')\n","print(cm)  # Provides details on how many frauds were correctly identified and how many were missed.\n","\n","# ---- Save the Trained Model ----\n","# The entire pipeline (including preprocessing and model) is saved using joblib for later use.\n","# This allows the model to be reloaded and used without needing retraining.\n","joblib.dump(pipeline, 'fraud_detection_pipeline.pkl')\n","print(\"Model saved successfully.\")\n","\n","#the output we got\n","#Accuracy: 98.21%\n","#F1-Score: 0.968967114404817\n","#Confusion Matrix:\n","#[[7921   79]\n","# [ 122 3138]]\n","#Model saved successfully.\n"]},{"cell_type":"code","execution_count":63,"metadata":{"execution":{"iopub.execute_input":"2024-09-19T10:47:49.478545Z","iopub.status.busy":"2024-09-19T10:47:49.478218Z","iopub.status.idle":"2024-09-19T10:48:03.849800Z","shell.execute_reply":"2024-09-19T10:48:03.848880Z","shell.execute_reply.started":"2024-09-19T10:47:49.478511Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["whole dataset\n","Accuracy: 98.64%\n","F1-Score: 0.9495272169690775\n","Confusion Matrix:\n","[[49929    71]\n"," [  719  7431]]\n","Model saved successfully.\n"]}],"source":["# Import libraries\n","#wholedataset\n","import pandas as pd\n","import joblib\n","from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n","from sklearn.compose import ColumnTransformer\n","from sklearn.pipeline import Pipeline\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.metrics import f1_score, confusion_matrix, accuracy_score\n","from sklearn.impute import SimpleImputer\n","\n","# Load the dataset from cleaned data CSV\n","df = pd.read_csv('/kaggle/input/datathon/DATATHON_EVENT_DATASET.csv')\n","\n","# ---- Data Cleaning (Handling missing values) ----\n","numerical_cols = df.select_dtypes(include=['float64', 'int64']).columns\n","categorical_cols = df.select_dtypes(include=['object']).columns\n","\n","# Impute missing values\n","df[numerical_cols] = SimpleImputer(strategy='median').fit_transform(df[numerical_cols])\n","df[categorical_cols] = SimpleImputer(strategy='most_frequent').fit_transform(df[categorical_cols])\n","\n","# ---- Label Conversion ----\n","df['Fraud'] = df['Fraud'].map({'Yes': 1, 'No': 0})\n","\n","# ---- Drop the 'Expected_Fraud' column ----\n","df = df.drop(columns=['Expected_Fraud'])\n","\n","# ---- Define Features (X) and Target (y) ----\n","X = df.drop(columns=['Fraud'])  # Features\n","y = df['Fraud']  # Target (fraud label)\n","\n","# ---- Handling High Cardinality Columns ----\n","label_encoder = LabelEncoder()\n","X['Origin_ID'] = label_encoder.fit_transform(X['Origin_ID'])\n","X['Destination_ID'] = label_encoder.fit_transform(X['Destination_ID'])\n","\n","# ---- One-Hot Encoding for Categorical Columns ----\n","categorical_cols = ['Transaction_Type']\n","preprocessor = ColumnTransformer(\n","    transformers=[('cat', OneHotEncoder(drop='first'), categorical_cols)],\n","    remainder='passthrough'\n",")\n","\n","# ---- Create the Pipeline ----\n","pipeline = Pipeline(steps=[\n","    ('preprocessor', preprocessor),\n","    ('scaler', StandardScaler()),\n","    ('classifier', RandomForestClassifier(n_estimators=200, max_depth=10, random_state=42))\n","])\n","\n","# ---- Train the Model ----\n","pipeline.fit(X, y)  # Train on the entire dataset\n","\n","# ---- Predictions and Evaluation ----\n","y_pred = pipeline.predict(X)\n","\n","# ---- Model Performance Evaluation ----\n","f1 = f1_score(y, y_pred)\n","cm = confusion_matrix(y, y_pred)\n","accuracy = accuracy_score(y, y_pred)\n","\n","# Print the evaluation metrics\n","print(\"whole dataset\")\n","print(f'Accuracy: {accuracy * 100:.2f}%')\n","print(f'F1-Score: {f1}')\n","print('Confusion Matrix:')\n","print(cm)\n","\n","# ---- Save the Trained Model ----\n","joblib.dump(pipeline, 'fraud_detection_pipeline_full.pkl')\n","print(\"Model saved successfully.\")\n","\n","#Accuracy: 98.64%\n","#F1-Score: 0.9495272169690775\n","#Confusion Matrix:\n","#[[49929    71]\n","# [  719  7431]]\n","#Model saved successfully."]},{"cell_type":"code","execution_count":64,"metadata":{"execution":{"iopub.execute_input":"2024-09-19T10:48:03.852047Z","iopub.status.busy":"2024-09-19T10:48:03.851726Z","iopub.status.idle":"2024-09-19T10:48:03.997346Z","shell.execute_reply":"2024-09-19T10:48:03.996462Z","shell.execute_reply.started":"2024-09-19T10:48:03.852015Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Test results\n","Accuracy: 99.45%\n","F1-Score: 0.9841269841269841\n","Confusion Matrix:\n","[[302   1]\n"," [  1  62]]\n"]}],"source":["# Import necessary libraries\n","import pandas as pd\n","import joblib\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.impute import SimpleImputer\n","from sklearn.metrics import f1_score, confusion_matrix, accuracy_score\n","\n","# Load the cleaned test dataset\n","df_test = pd.read_csv('/kaggle/input/test-dataset/Test.csv')  # Replace with your test dataset path\n","\n","# ---- Test Data Preprocessing ----\n","# Impute missing values for numerical and categorical columns\n","numerical_cols = df_test.select_dtypes(include=['float64', 'int64']).columns\n","categorical_cols = df_test.select_dtypes(include=['object']).columns\n","\n","# Impute missing values (the same strategy used during training)\n","df_test[numerical_cols] = SimpleImputer(strategy='median').fit_transform(df_test[numerical_cols])\n","df_test[categorical_cols] = SimpleImputer(strategy='most_frequent').fit_transform(df_test[categorical_cols])\n","\n","# Convert 'Yes'/'No' in 'Fraud' column to 1 and 0\n","df_test['Fraud'] = df_test['Fraud'].map({'Yes': 1, 'No': 0})\n","\n","# Drop the 'Expected_Fraud' column if it exists\n","df_test = df_test.drop(columns=['Expected_Fraud'], errors='ignore')\n","\n","# Define features and target for the test data\n","X_test = df_test.drop(columns=['Fraud'])  # Test features\n","y_test = df_test['Fraud']  # Test target (fraud label)\n","\n","# ---- Label Encoding for High-Cardinality Columns ----\n","# Ensure that the same LabelEncoder is applied to the test data\n","# Load the LabelEncoder (apply the same transformation as done during training)\n","label_encoder = LabelEncoder()\n","X_test['Origin_ID'] = label_encoder.fit_transform(X_test['Origin_ID'])\n","X_test['Destination_ID'] = label_encoder.fit_transform(X_test['Destination_ID'])\n","\n","# Load the saved model pipeline\n","model = joblib.load('fraud_detection_pipeline.pkl')\n","\n","# ---- Test the Model ----\n","# Make predictions using the loaded model\n","y_pred = model.predict(X_test)\n","\n","# ---- Evaluate the Model ----\n","# Calculate F1 Score, Confusion Matrix, and Accuracy\n","f1 = f1_score(y_test, y_pred)\n","cm = confusion_matrix(y_test, y_pred)\n","accuracy = accuracy_score(y_test, y_pred)\n","\n","# Print the evaluation metrics\n","print(\"Test results\")\n","print(f'Accuracy: {accuracy * 100:.2f}%')\n","print(f'F1-Score: {f1}')\n","print('Confusion Matrix:')\n","print(cm)\n","\n","#Accuracy: 99.45%\n","#F1-Score: 0.9841269841269841\n","#Confusion Matrix:\n","#[[302   1]\n","# [  1  62]]"]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"datasetId":5731113,"sourceId":9432914,"sourceType":"datasetVersion"},{"datasetId":5731878,"sourceId":9433943,"sourceType":"datasetVersion"},{"datasetId":5732073,"sourceId":9434214,"sourceType":"datasetVersion"}],"dockerImageVersionId":30762,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.14"}},"nbformat":4,"nbformat_minor":4}
